{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Week5]GAT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp8ub0e1n+ZSwNm+1SJW0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimyuji/RecSys_DSAIL/blob/main/%5BWeek5%5DGAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH-w7HVu7E3A"
      },
      "source": [
        "### GAT 노션 정리\n",
        "https://www.notion.so/GCN-Semi-Supervised-Classification-with-Graph-Convolutional-Network-6162397d48964a6baece04c3b7a5ecaf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnP6JFwmSimJ"
      },
      "source": [
        "pip install dgl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vRJymvuScgj",
        "outputId": "de45727f-9056-4247-c962-d269ac69f077"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Deep Graph Library\n",
        "from dgl import DGLGraph\n",
        "import dgl\n",
        "\n",
        "from dgl.data import CitationGraphDataset\n",
        "citeseer = CitationGraphDataset('citeseer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading /root/.dgl/citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n",
            "Extracting file to /root/.dgl/citeseer\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/citation_graph.py:258: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2i2I-1FUAe4"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7umQf3UTbMF"
      },
      "source": [
        "def load_citeseer_data():\n",
        "    data = citeseer\n",
        "    features = torch.FloatTensor(data.features)\n",
        "    labels = torch.LongTensor(data.labels)\n",
        "    mask = torch.BoolTensor(data.train_mask)\n",
        "    g = data.graph\n",
        "    \n",
        "    # add self loop\n",
        "    # GAT는 i <-> i의 self-attention도 종합하기 때문에 해당 정보를 edge에 추가해준다\n",
        "    g.remove_edges_from(nx.selfloop_edges(g))\n",
        "    g = DGLGraph(g)\n",
        "    g.add_edges(g.nodes(), g.nodes())\n",
        "    return g, features, labels, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9qPa744UKMj",
        "outputId": "49176e15-339f-47f2-ca41-9adaa0f54c1f"
      },
      "source": [
        "citeseer.features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3327, 3703])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqR8tJB7UKEe",
        "outputId": "74c24741-657d-42e1-b056-f328fcccd581"
      },
      "source": [
        "citeseer.labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3327,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obe4-7aKU_kg",
        "outputId": "24bf0ac1-9648-4f97-909b-6c377e1a9ebd"
      },
      "source": [
        "citeseer.train_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3327,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PljatCivVERJ",
        "outputId": "a1e727ed-ce97-4815-fce7-1d30a3131051"
      },
      "source": [
        "citeseer.graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.digraph.DiGraph at 0x7fcda8d582b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gChvzy5gUJkx"
      },
      "source": [
        "## 2. Define a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X4g5H_1Saw0"
      },
      "source": [
        "class GATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim):\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.g = g\n",
        "        \n",
        "        # Expression 3\n",
        "        # F-Dimension의 피쳐 스페이스가 single fc-layer 지나며 F'-Dimension으로 임베딩 \n",
        "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
        "        # i노드의 F' + j노드의 F' 길이의 벡터를 합쳐서 Attention Coefficient를 리턴 \t\n",
        "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
        "\n",
        "        \n",
        "    # Expression 3에서 어텐션으로 넘어온 값을 Leaky Relu 적용하는 Layer\n",
        "\t# src는 source vertex, dst는 destination vertex의 약자\t\n",
        "    def edge_attention(self, edges):\n",
        "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
        "        a = self.attn_fc(z2)\n",
        "        return {'e': F.leaky_relu(a)}\n",
        "\n",
        "    \n",
        "    # dgl에서는 모든 노드에 함수를 병렬 적용 할 수 있는 update_all 이라는 api를 제공한다.\n",
        "    # 해당 api 사용을 위해 텐서를 흘려보내는 역할을 한다고 한다.\n",
        "\t# 구체적인 update_all의 알고리즘은 잘 모르겠으니 그냥 input 함수라고 생각하자.\n",
        "    def message_func(self, edges):\n",
        "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
        "\n",
        "\n",
        "    # update_all에서는 흘려보내진 텐서를 각 노드의 mailbox라는 오브젝트에 저장하나 보다.\n",
        "    # 각 노드에는 여러 이웃이 있으니 mailbox에는 여러개의 attention coefficient가 있다.\n",
        "    # Expression 4에서 softmax 계수를 가중하여 element wise하게 합한다.  \n",
        "    def reduce_func(self, nodes):\n",
        "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
        "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
        "        return {'h': h}\n",
        "\n",
        "    \n",
        "    # (1) fc layer를 통해 피쳐를 임베딩\n",
        "    # (2) 그레프에 임베딩 된 벡터를 저장\n",
        "    # (3) apply_edges api를 모든 엣지에 적용하여 i - j 간의 attention coefficeint를 계산\n",
        "    # (4) 그래프에 저장된 z와e를 텐서로 reduce_func에 전달하여 새로운 h' 를 얻는다.\n",
        "    def forward(self, h):\n",
        "        z = self.fc(h)\n",
        "        self.g.ndata['z'] = z\n",
        "        self.g.apply_edges(self.edge_attention)\n",
        "        self.g.update_all(self.message_func, self.reduce_func)\n",
        "        return self.g.ndata.pop('h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijj1048DTVju"
      },
      "source": [
        "class MultiHeadGATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
        "        super(MultiHeadGATLayer, self).__init__()\n",
        "        self.heads = nn.ModuleList()\n",
        "        for i in range(num_heads):\n",
        "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
        "        self.merge = merge\n",
        "\n",
        "    def forward(self, h):\n",
        "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
        "        if self.merge == 'cat':\n",
        "            # concat on the output feature dimension (dim=1)\n",
        "            return torch.cat(head_outs, dim=1)\n",
        "        else:\n",
        "            # merge using average\n",
        "            return torch.mean(torch.stack(head_outs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpU-pLkaTWd7"
      },
      "source": [
        "class GAT(nn.Module):\n",
        "    \n",
        "    # 두 Layer의 인풋과 아웃풋이 다른 것을 볼 수 있다\n",
        "    # 원래 노드의 feature 개수가 F개라고 했을 때, layer를 한 번 지나며 F'개로 임베딩했다.\n",
        "    # 이것을 num_heads(attention 개수) 만큼 multi-head하게 보아 K*F' 길이로 cat했다.\n",
        "    # 두 번째 layer에서는 K를 1로 설정하여 single-head attention을 적용했다.  \n",
        "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
        "        super(GAT, self).__init__()\n",
        "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
        "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
        "\n",
        "    def forward(self, h):\n",
        "        h = self.layer1(h)\n",
        "        h = F.elu(h)\n",
        "        h = self.layer2(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9d2qR5KTdkC",
        "outputId": "5c8d55cc-313a-44c4-fad8-e5c52bf63d4d"
      },
      "source": [
        "g, features, labels, mask = load_citeseer_data()\n",
        "train_loss = []\n",
        "\n",
        "# create the model, 2 heads, each head has hidden size 8\n",
        "net = GAT(g,\n",
        "          in_dim=features.size()[1],\n",
        "          hidden_dim=8,\n",
        "          out_dim=6,\n",
        "          num_heads=2)\n",
        "\n",
        "# create optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "# main loop\n",
        "dur = []\n",
        "for epoch in range(1000):\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    logits = net(features)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[mask], labels[mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "        \n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}\".format(\n",
        "          epoch, loss.item(), np.mean(dur)))\n",
        "    train_loss.append(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
            "  return warnings.warn(message, category=category, stacklevel=1)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Loss 1.7917 | Time(s) nan\n",
            "Epoch 00100 | Loss 1.6258 | Time(s) 0.1818\n",
            "Epoch 00200 | Loss 1.2514 | Time(s) 0.1810\n",
            "Epoch 00300 | Loss 0.7947 | Time(s) 0.1806\n",
            "Epoch 00400 | Loss 0.4392 | Time(s) 0.1805\n",
            "Epoch 00500 | Loss 0.2433 | Time(s) 0.1802\n",
            "Epoch 00600 | Loss 0.1396 | Time(s) 0.1803\n",
            "Epoch 00700 | Loss 0.0868 | Time(s) 0.1814\n",
            "Epoch 00800 | Loss 0.0583 | Time(s) 0.1820\n",
            "Epoch 00900 | Loss 0.0415 | Time(s) 0.1826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-SCg_5OThAV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_arr)\n",
        "display(plt.show())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPlfNmyWUY2g"
      },
      "source": [
        "mask = torch.BoolTensor(citeseer.test_mask)\n",
        "\n",
        "pred = np.argmax(logp[mask].detach().numpy(), axis = 1)\n",
        "answ = labels[mask].numpy()\n",
        "np.sum([1 if pred[i] == answ[i] else 0 for i in range(len(pred))]) / len(pred) * 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D59ZKLbOUyGH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}